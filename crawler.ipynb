{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def download_post_by_shortcode(shortcode):\n",
    "    # download a specific post by shortcode\n",
    "    import instaloader\n",
    "    L = instaloader.Instaloader()\n",
    "    \n",
    "    try:\n",
    "        # Load the post by shortcode\n",
    "        post = instaloader.Post.from_shortcode(L.context, shortcode)\n",
    "        print(f\"Downloading post {shortcode}...\")\n",
    "        L.download_post(post, target=post.owner_username)\n",
    "        print(f\"Post {shortcode} has been downloaded.\")\n",
    "    except Exception as e:\n",
    "        print(f\"An error occurred: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_urls(usernames):\n",
    "    from selenium import webdriver\n",
    "    from selenium.webdriver.common.keys import Keys\n",
    "    from selenium.webdriver.common.by import By\n",
    "    import time\n",
    "    from dotenv import load_dotenv\n",
    "    import os\n",
    "    \n",
    "    load_dotenv()\n",
    "    \n",
    "    IG_USER = os.getenv(\"IG_USER\")\n",
    "    IG_PASSWORD = os.getenv(\"IG_PASSWORD\")\n",
    "\n",
    "    SCROLL_PAUSE = 3\n",
    "    options = webdriver.ChromeOptions()\n",
    "    options.add_experimental_option(\"detach\", True)\n",
    "\n",
    "    # driver = webdriver.Chrome(options=options)\n",
    "    driver = webdriver.Chrome()\n",
    "    \n",
    "    # login to Instagram\n",
    "    driver.get(\"https://www.instagram.com/accounts/login/\")\n",
    "    time.sleep(5)\n",
    "\n",
    "    # Fill in login form\n",
    "    driver.find_element(By.NAME, \"username\").send_keys(IG_USER)\n",
    "    driver.find_element(By.NAME, \"password\").send_keys(IG_PASSWORD)\n",
    "    driver.find_element(By.NAME, \"password\").send_keys(Keys.RETURN)\n",
    "    time.sleep(8)\n",
    "    \n",
    "    \n",
    "    # Iterate through each username\n",
    "    all_urls = []\n",
    "    for username in usernames:\n",
    "        driver.get(f\"https://www.instagram.com/{username}/\")\n",
    "        time.sleep(5)\n",
    "        # return\n",
    "        \n",
    "        # Scroll a few times to load more posts\n",
    "        SCROLL_PAUSE = 4\n",
    "        last_height = driver.execute_script(\"return document.body.scrollHeight\")\n",
    "        post_urls = set()\n",
    "\n",
    "        while True:\n",
    "            # Scroll to bottom\n",
    "            driver.execute_script(\"window.scrollTo(0, document.body.scrollHeight);\")\n",
    "            time.sleep(SCROLL_PAUSE)\n",
    "\n",
    "            # Extract new post links\n",
    "            links = driver.find_elements(By.TAG_NAME, \"a\")\n",
    "            for link in links:\n",
    "                href = link.get_attribute(\"href\")\n",
    "                if href and \"/p/\" in href:\n",
    "                    post_urls.add(href)\n",
    "\n",
    "            # Check if new scroll height has changed\n",
    "            new_height = driver.execute_script(\"return document.body.scrollHeight\")\n",
    "            if new_height == last_height:\n",
    "                print(\"üîΩ Reached end of page.\")\n",
    "                break\n",
    "            last_height = new_height\n",
    "\n",
    "\n",
    "        # Collect post URLs\n",
    "        links = driver.find_elements(By.TAG_NAME, \"a\")\n",
    "        for link in links:\n",
    "            href = link.get_attribute(\"href\")\n",
    "            if href and \"/p/\" in href:\n",
    "                post_urls.add(href)\n",
    "        post_urls = list(set(post_urls))\n",
    "        all_urls.extend(post_urls)\n",
    "        \n",
    "    driver.quit()\n",
    "    \n",
    "    return all_urls\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_shortcode_from_url(url):\n",
    "    return url.split(\"/\")[-2] if \"/p/\" in url else None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_all_user():\n",
    "    import os\n",
    "    not_user_dirs = ['.git', '.vscode', 'venv', '__pycache__', 'raw_data', 'final_data']\n",
    "    # get all username directory under this directory\n",
    "    current_dir = os.getcwd()\n",
    "    user_dirs = [d for d in os.listdir(current_dir) if os.path.isdir(os.path.join(current_dir, d)) and not d.startswith('.')]\n",
    "    # remove directories that are not user directories\n",
    "    user_dirs = [d for d in user_dirs if d not in not_user_dirs]\n",
    "    return user_dirs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def organize_posts_by_timestamp(user_dir):\n",
    "    import os\n",
    "    import shutil\n",
    "    import re\n",
    "    # Regex to extract the prefix: e.g., 2018-02-17_09-05-15_UTC\n",
    "    prefix_pattern = re.compile(r'^(\\d{4}-\\d{2}-\\d{2}_\\d{2}-\\d{2}-\\d{2}_UTC)')\n",
    "    user_name = os.path.basename(user_dir)\n",
    "\n",
    "    # List all files in the user directory\n",
    "    for file in os.listdir(user_dir):\n",
    "        file_path = os.path.join(user_dir, file)\n",
    "\n",
    "        # Skip directories\n",
    "        if os.path.isdir(file_path):\n",
    "            continue\n",
    "\n",
    "        match = prefix_pattern.match(file)\n",
    "        if match:\n",
    "            prefix = match.group(1)\n",
    "            post_dir = os.path.join(user_dir, f'{user_name}_{prefix}')\n",
    "            os.makedirs(post_dir, exist_ok=True)\n",
    "\n",
    "            # Move the file into the corresponding post directory\n",
    "            target_path = os.path.join(post_dir, file)\n",
    "            shutil.move(file_path, target_path)\n",
    "            print(f\"üìÇ Moved {file} ‚Üí {post_dir}/\")\n",
    "\n",
    "    print(\"‚úÖ Organization complete.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_post_directory(post_dir):\n",
    "    import os\n",
    "    import shutil\n",
    "    import re\n",
    "    \n",
    "    post_data = {}\n",
    "\n",
    "    # --- Step 1: Find the .txt file ---\n",
    "    txt_file = next((f for f in os.listdir(post_dir) if f.endswith('.txt')), None)\n",
    "    if not txt_file:\n",
    "        print(f\"‚ö†Ô∏è No .txt file found in {post_dir}\")\n",
    "        return None\n",
    "\n",
    "    txt_path = os.path.join(post_dir, txt_file)\n",
    "    with open(txt_path, 'r', encoding='utf-8') as f:\n",
    "        text = f.read().strip()\n",
    "\n",
    "    # --- Step 2: Extract hashtags ---\n",
    "    hashtags = re.findall(r\"#\\w+\", text)\n",
    "\n",
    "    # --- Step 3: Find the image file ---\n",
    "    image_file = None\n",
    "    for name in sorted(os.listdir(post_dir)):\n",
    "        if re.match(r\".*_1\\.jpg$\", name):\n",
    "            image_file = name\n",
    "            break\n",
    "    if not image_file:\n",
    "        # fallback: try single image (e.g., timestamp.jpg)\n",
    "        jpg_files = [f for f in os.listdir(post_dir) if f.endswith(\".jpg\")]\n",
    "        if jpg_files:\n",
    "            image_file = sorted(jpg_files)[0]  # take the first one\n",
    "\n",
    "    if not image_file:\n",
    "        print(f\"‚ö†Ô∏è No image file found in {post_dir}\")\n",
    "        return None\n",
    "\n",
    "    image_src_path = os.path.join(post_dir, image_file)\n",
    "    image_dst_dir = os.path.join(\"final_data\", \"images\")\n",
    "    os.makedirs(image_dst_dir, exist_ok=True)\n",
    "    image_dst_path = os.path.join(image_dst_dir, image_file)\n",
    "\n",
    "    shutil.copy(image_src_path, image_dst_path)\n",
    "\n",
    "    # --- Step 4: Build relative image path ---\n",
    "    image_path = os.path.relpath(image_dst_path, \"final_data\")\n",
    "\n",
    "    # --- Step 5: Get author from parent directory ---\n",
    "    author = os.path.basename(os.path.dirname(post_dir))\n",
    "\n",
    "    # --- Step 6: Construct post dictionary ---\n",
    "    post_data = {\n",
    "        \"text\": text,\n",
    "        \"image_path\": image_path.replace(\"\\\\\", \"/\"),  # for Windows compatibility\n",
    "        \"author\": author,\n",
    "        \"hashtags\": hashtags\n",
    "    }\n",
    "\n",
    "    return post_data\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Main program"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# read account_list.csv and return a list of usernames\n",
    "import pandas as pd\n",
    "df = pd.read_csv('account_list.csv')\n",
    "original_accounts = df['ig Â∏≥Ëôü'].tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# some metadata\n",
    "original_accounts_count = len(original_accounts)\n",
    "post_count = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "original_accounts = [\"omega_3iana\"]\n",
    "post_count = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get all posts urls\n",
    "urls = get_urls(original_accounts)\n",
    "# get all shortcodes from urls\n",
    "shortcodes = [get_shortcode_from_url(url) for url in urls if get_shortcode_from_url(url)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# download posts by shortcodes\n",
    "for shortcode in shortcodes:\n",
    "    download_post_by_shortcode(shortcode)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get all user directories and move them to raw_data\n",
    "import os\n",
    "users = get_all_user()\n",
    "\n",
    "# move all user directories to raw_data\n",
    "for user_dir in users:\n",
    "    if not os.path.exists('raw_data'):\n",
    "        os.makedirs('raw_data')\n",
    "    src = os.path.join(os.getcwd(), user_dir)\n",
    "    dst = os.path.join(os.getcwd(), 'raw_data', user_dir)\n",
    "    if os.path.exists(dst):\n",
    "        print(f\"Directory {dst} already exists, skipping.\")\n",
    "    else:\n",
    "        print(f\"Moving {src} to {dst}...\")\n",
    "        os.rename(src, dst)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# make each post data a subdirectory of the user directory\n",
    "for user_dir in users:\n",
    "    user_path = os.path.join('raw_data', user_dir)\n",
    "    if not os.path.exists(user_path):\n",
    "        print(f\"User directory {user_path} does not exist, skipping.\")\n",
    "        continue\n",
    "    organize_posts_by_timestamp(user_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# make each post a data in posts.json\n",
    "import json\n",
    "\n",
    "all_posts = []\n",
    "# iterate through each user directory in raw_data\n",
    "for user_dir in users:\n",
    "    user_path = os.path.join('raw_data', user_dir)\n",
    "    if not os.path.exists(user_path):\n",
    "        print(f\"User directory {user_path} does not exist, skipping.\")\n",
    "        continue\n",
    "    \n",
    "    # iterate through each post directory\n",
    "    for post_dir in os.listdir(user_path):\n",
    "        post_path = os.path.join(user_path, post_dir)\n",
    "        if not os.path.isdir(post_path):\n",
    "            continue\n",
    "        \n",
    "        post_data = process_post_directory(post_path)\n",
    "        post_count += 1\n",
    "        if post_data:\n",
    "            all_posts.append(post_data)\n",
    "            print(f\"Processed post: {post_data['image_path']} by {post_data['author']}\")\n",
    "            \n",
    "with open('final_data/data/posts.json', 'w', encoding='utf-8') as f:\n",
    "    json.dump(all_posts, f, ensure_ascii=False, indent=4)\n",
    "        "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "SMA-final-data",
   "language": "python",
   "name": "venv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
